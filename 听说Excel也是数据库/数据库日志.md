# 数据库日志
>2017-02-17 20:30 

## Oracle
* 日期比较
	 ```sql
	select (case when a>to_date('2016-10-28','yyyy-mm-dd') then a else to_date('2016-10-28','yyyy-mm-dd') end)  from test
	```
* 批量存储
	```sql
	DECLARE
	  i number := 0;
	BEGIN
	  for i in 1 .. 1000 loop
	    insert into A_PROJECT_TOOL_GT_FORCAST 
	    (project_id, project_name, type,status) values (i,'test',1,1);
	  end loop;
	  commit;
	END;
	```
* 外链接
	`SELECT a.*, b.* from a(+) = b` 右连接 , 等同于`select a.*, b.* from a right join b`
	`SELECT a.*, b.* from a = b(+)` 左连接 , 等同于`select a.*, b.* from a left join b`
## MySql

### 零散的SQL

* 相同列拼接
	```sql
	SELECT GROUP_CONCAT(id) id  FROM category
	--默认情况下是以 , 进行分割 , 另外默认长度为1024, 超出长度需要设置
	SET GLOBAL group_concat_max_len=102400;
	```
* 常用函数

  ```sql
  SELECT CHAR_LENGTH('你好123') -- 5
  SELECT LENGTH('你好123') -- 9
  SELECT CONCAT('12','34') -- 1234
  SELECT CONCAT_WS('@','12','34') -- 12@34 同CONCAT(s1,s2,...) 函数 , 但是每个字符串直接要加上x
  SELECT LEFT('abcde',2) -- ab 返回字符串s的前n个字符
  SELECT RIGHT('abcde',2) -- de
  SELECT TRIM('@' FROM '@@abc@@') -- abc 去掉字符串s中开始处和结尾处的字符串s1
  SELECT STRCMP('A',''B) ---字符串比较
  SELECT SUBSTRING(s,n,len) ---获取从字符串s中的第n个位置开始长度为len的字符串
  SELECT LOCATE('b', 'abc') -- 2 从字符串s中获取s1的开始位置
  SELECT FIELD('c','a','b','c') -- 3 FIELD(s,s1,s2...) 返回第一个与s匹配的字符串位置
  SELECT FIND_IN_SET(s1,s2) --s1是单个字符 ,s2为 , 分割的字符串 . 结果是s1在s2里面的位置
  SELECT CURRENT_DATE()-- 当前时间
  SELECT SHORT_UUID()--用途还未十分清晰
  select SUBSTRING_INDEX("test.changdy",".",-1) name -- substring_index 方法
  ```

### information_schema库信息

* 查看表详情

  ```sql
  SELECT
    COLUMN_NAME                    AS `行`,
    COLUMN_TYPE                    AS `类型`,
    COLUMN_COMMENT                 AS `备注`,
    concat(COLUMN_KEY, ' ', EXTRA) AS `其他信息`,
    COLUMN_DEFAULT                 AS `默认`,
    IS_NULLABLE                    AS `允许空`,
    CHARACTER_SET_NAME             AS `编码`,
    COLLATION_NAME                 AS `排序集`,
    ORDINAL_POSITION               AS `顺序`
  FROM information_schema.COLUMNS WHERE TABLE_NAME = 'or_rescue_order';
  ```

* 查看线程信息

  ```sql
  SELECT *FROM information_schema.processlist;
  ```

* 查看表详情

  ```sql
  SELECT *FROM information_schema.TABLES WHERE TABLE_SCHEMA = 'information_schema';
  ```

### MySql批量更新方案

MySql并不支持像 Insert一样直接批量更新 , 以下是几种比较折中的方案

* 利用update case when

  ```sql
  UPDATE yoiurtable
      SET dingdan = CASE id WHEN 1 THEN 3 WHEN 2 THEN 4  WHEN 3 THEN 5  END
  WHERE id IN (1,2,3)
  ```

* 关联update

  把数据插入到一张临时表中 然后和临时表进行关联 , 执行update

* 主键创建唯一索引 , 然后利用索引执行更新:

  * insert into ...duplicate key

    ```sql
    insert into book (`Id`,`Author`,`CreatedTime`,`UpdatedTime`) values 
    (1,'张飞2','2017-12-12','2017-12-12'),(2,'关羽2','2017-12-12','2017-12-12') 
    on duplicate key update Author=values(Author) ,CreatedTime=values(CreatedTime) ,UpdatedTime=values(UpdatedTime);
    ```

  * replace into

    ```sql
    replace into book (`Id`,`Author`,`CreatedTime`,`UpdatedTime`) values 
    (1,'张飞2','2017-12-12','2017-12-12'),(2,'关羽2','2017-12-12','2017-12-12') 
    ```

  两者的不同之处在于 replace into 操作本质是对重复的记录先delete 后insert，如果更新的字段不全会将缺失的字段置为缺省值，用这个要悠着点否则不小心清空大量数据可不是闹着玩的。insert into 则是只update重复记录，不会改变其它字段。

### MySql优化

* 避免隐式转换
* 查询字段尽量避免null
* 合理使用联合索引以及覆盖索引
* 避免使用in查询 (会导致临时表 , 增加io和网络)
* 利用schema_redundant_indexes 查看多余索引
* Profile:查询到 SQL 会执行多少时间 , 并看出 CPU/Memory 使用量 , 执行过程中 Systemlock, Table lock 花多少时间等等
* 确定只有一条数据时 , 可以使用limit1
* 可以考虑使用mysql的分区

### [explain](https://zhuanlan.zhihu.com/p/51771446) 性能分析

- id: SELECT 查询的标识符 . 每个 SELECT 都会自动分配一个唯一的标识符 .

- select_type: SELECT 查询的类型 .

- table: 查询的是哪个表

- type: join 类型``ALL < index < range ~ index_merge < ref < eq_ref < const < system``

- possible_keys: 此次查询中可能选用的索引

- key: 此次查询中确切使用到的索引 .

- ref: 哪个字段或常数与 key 一起被使用

- rows: 显示此查询一共扫描了多少行 . 这个是一个估计值 .

- filtered: 表示此查询条件所过滤的数据的百分比

- extra:

  Using index : 使用覆盖索引 , 表示查询索引就可查到所需数据 不需要回表
  Using Where : 在存储引擎检索行后再进行过滤 , 使用了where从句来限制哪些行将与下一张表匹配或者是返回给用户 .
  Using temporary : 使用了临时表
  Using filesort : 使用了外部索引排序

### MySql锁相关

#### InnoDB

同时支持行级锁和表级锁 ; 行级锁是基于索引实现的 , 当给一张表上行锁的时候  , 会同时给表加入意向锁 .这个时候如果有其他线程再申请表级锁则会失败 . 但是行级锁正常

#### MyISAM

只支持表级锁 , 简单粗暴

## Redis

### Redis持久化策略

* 快照持久化 (RDB)

  默认情况下使用该种策略 . Redis可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis主从结构，主要用来提高Redis性能），还可以将快照留在原地以便重启服务器的时候使用。

* AOF持久化

  与快照持久化相比，AOF持久化 的实时性更好，因此已成为主流的持久化方案。开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件。

**Redis 4.0 对于持久化机制的优化**

Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 `aof-use-rdb-preamble` 开启）。

如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。另外Redis在持久化的时候时多线程

### Redis key过期策略

- **定期删除**：redis默认是每隔 100ms 就**随机抽取**一些设置了过期时间的key，检查其是否过期，如果过期就删除 . 
- **惰性删除** ： 由于定期删除并不能一定保证过期KEY被删除 , 因此有了惰性删除策略:即对过期进行操作的时候Redis会立刻删除该key , 并返回 nil

可见Redis的key过期其实也是轮询 , 而非高科技 . 并且还不能保证到时间一定会被删除 . 当初同事有想用这个实现一个过期监听 . 也是由于key过期策略的不稳定被坑了

### 其他

- 缓存雪崩 : 缓存短时间内失效 , 解决方法 失效时间加随机数
- 缓存穿透 : 访问了大量假数据 , 解决方法:黑名单+key值存放

### **Redis 数据淘汰策略**

* volatile-lru：         从设置过期时间的数据集中挑选最近最少使用的数据
* volatile-ttl：          从-----------------------------------------将要过期的数据
* volatile-random：从-----------------------------------------任意数据
* allkeys-lru：移除最近最少使用的key（这个是最常用的）
* allkeys-random：任意数据
* no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！
* volatile-lfu：          从-----------------------------------------最不经常使用的数据
* allkeys-lfu：移除最不经常使用的key

## SQL执行顺序
* 在查询过程中聚合语句 (sum,min,max,avg,count) 要比having子句优先执行 . 而where子句在查询过程中执行优先级别优先于聚合语句 .having就是来弥补where在分组数据判断时的不足 . 因为where执行优先级别要快于聚合语句 .