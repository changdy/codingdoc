# 分析一次数据库事务导致的事故

> 大概上个月系统出现了一些故障 , 时隔一个月系统已经逐渐恢复稳定. 写下此文章吸取教训

## MySql 方向

* 查看数据库锁信息

  ```sql
  -- 查看事务
  SELECT *FROM information_schema.INNODB_TRX;
  -- 查看锁
  SELECT *FROM information_schema.INNODB_LOCKS;
  -- 查看锁等待
  SELECT *FROM information_schema.INNODB_LOCK_WAITS;
  -- 关联查询,等待锁被那个锁锁住 8.0+失效
  SELECT
    r.trx_id              waiting_trx_id,
    r.trx_mysql_thread_id waiting_thread,
    r.trx_query           waiting_query,
    b.trx_id              blocking_trx_id,
    b.trx_mysql_thread_id blocking_thread,
    b.trx_query           blocking_query
  FROM information_schema.innodb_lock_waits w INNER JOIN information_schema.innodb_trx b ON b.trx_id = w.blocking_trx_id
    INNER JOIN information_schema.innodb_trx r ON r.trx_id = w.requesting_trx_id;
  -- 查询视图
  select *from sys.schema_table_lock_waits;
  ```

* 默认隔离级别为 `重复读` , 改成`提交读` 会缓解一部分压力 , (需要业务支持)

* `select *** for update` 是当前读 , 会读取到所有的已经提交的数据

* `sync_binlog ` 和`innodb_flush_log_at_trx_commit` 配合修改可以增加 数据库的io [【MySQL】sync_binlog innodb_flush_log_at_trx_commit 浅析](http://blog.itpub.net/22664653/viewspace-1063134/)

* 说一条语句不在事务中其实有些不准确 ,在MySql中任何一条语句都是一个事务 , 只是有些事务会自动提交

* 可以通过添加索引降低数据库锁粒度 , 减少锁竞争情况

* 尽量让MySql 只承担数据的搜索 , 计算相关的尽量挪到代码中执行 . 

* 批量更新 SQL , `insert into ** on duplicate key update`比逐条`update`效率更高, 但有可能带来更大的锁开销

* `1-N` 关联查询中,如果对于每个1 ,只取N中的固定某条数据,则最好在代码中拼装 例如:
  
  ```sql
  --- group by之后的效率非常差.并且可能带来外部排序
  select 订单表.*,group_concat(商品明细表.商品名称)
  from 订单表,商品明细表
  where 订单表.id=商品明细表.订单表
  group by 订单表.id
  --- 可以尝试在代码里进行sql拼接
  select * from 订单表;
  select group_concat(商品明细表.商品名称) from 商品明细表 where 商品明细表.订单表 =id;
  --- 写成一条sql查询效率也挺高
  select 订单表.*,(select group_concat(商品明细表.商品名称) from 商品明细表 where 订单表.id=商品明细表.订单表)  from 订单表;
  ```
* 针对分页需要进行优化
  
  * 去掉多余的关联和计算 , 以刚才订单查询为例,查询总数的时候可以去掉与`商品明细表`的关联,并确保查询的列只有 count(*)
  
  * 避免 limit 10000,10 的发生,如果需要的话 可以把上个分页的最大数据取出当作下一次分页的条件,比如:
  
    ```sql
    select id from task order by id limit 10000,10;
    --- 59454,59455,59456,59457,59458,59459,59460,59461,59462,59463
    select id from task where id >59463  order by id limit 0,10;
    ```
## JAVA 方向

Spring 可以通过 `@Transactional`注解提供了数据库事务的支持 ,相比较而言对用户比较透明.因此也导致了事务的滥用 , 以下是我遇到过的一些滥用场景:

* 直接注释到类上 , 将会导致类下所有的方法都会被包裹在事务中

* 注释的方法内有耗时操作, 将会导致其他线程一直等待,甚至超时异常

* 没有进行数据合理的校验 ,把数据库当作校验工具,导致数据频繁的回滚

* 没有正确的理解事务 , 比如有些日志表,非关键信息的流水表其实也无需事务

  公司有张车辆当前GPS经纬度表 , 因为这种表即便插入失败也影响不大, 所以完全没必要加入事务

### @Transactional之实现

Transactional 也是利用`Spring aop`实现的 , 当执行需要事务的方法时, `spring aop `会自动 执行`set autocommit =0` ,并将该数据库链接对象与当前方法绑定 ,此时可用的数据库链接对象将会减少一个. 而针对无需事务的方法 , 方法并不会持有数据库链接对象  , 因此前后两条sql 也有可能使用了不同的数据库链接对象.

单单说明有些枯燥 , 下面举例说明, 并假设Spring boot项目的最大连接池数量是2

```java
@RestController
public class TestController {
    @RequestMapping("/test-tx")
    @Transactional
    public void insertWithTransactional() throws InterruptedException {
        // 执行sql语句
        Thread.sleep(3000);
    }
    @RequestMapping("/no-tx")
    public void insertWithoutTransactional() throws InterruptedException {
        // 执行sql语句
        Thread.sleep(3000);
    }
}
```

在3S内连续两个接口三次 , 并观察情况

* test-tx

  第一次,第二次都正常, 第三次的时候请求进入等待 , 并且通过mysql `general_log`可以发现,前两次请求各自使用了一个链接

* no-tx

  第三次请求没有进入等待 , 并且三次请求使用了同一链接

## 故障分析与总结

故障发生时 , 表现为数据库锁比较多,数据连接数增加 , 接口超时

我推测的原因是因为 系统中的事务释放太慢 , 跟不上请求. 导致系统数据库连接池被占满 , 新的请求都被阻塞 , 客户打开页面后又认为服务器没响应 也不断刷新. 导致请求数量激增.并且项目没有设置请求超时时间. 

之后的处理思路主要就是围绕着 精简事务展开.另外也建议系统设置请求的超时时间.

总结比较简单 , 谨慎的使用事务,未必只有死锁导致系统无法请求数据库, 当连接池被带有事务的方法榨干之后依旧也会导致事故